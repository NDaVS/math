


\setcounter{section}{0} % Устанавливаем начальное значение для раздела
\renewcommand\thesection{\arabic{section}} % Устанавливаем формат номера раздела как просто цифру
\label{cha:analysis}
\chapter{Теоретическая часть}

\section{Математическое описание модели \texttt{multinom}}

Модель \texttt{multinom} основана на многочленной логистической регрессии, которая используется для предсказания категориальной зависимой переменной с \( K \) классами (\( K > 2 \)) на основе вектора признаков \( \mathbf{x} \in \mathbb{R}^p \).

\subsection{Вероятности классов (\textbf{softmax})}
Вероятность принадлежности наблюдения \( i \)-му классу \( k \) задаётся следующим выражением:
\[
P(y_i = k \mid \mathbf{x}_i) = 
\frac{\exp(\beta_{k0} + \mathbf{\beta}_k^\top \mathbf{x}_i)}{
	1 + \sum_{j=1}^{K-1} \exp(\beta_{j0} + \mathbf{\beta}_j^\top \mathbf{x}_i)}, \quad k = 1, \dots, K-1.
\]
Для последнего класса (\( k = K \)) используется нормализация:
\[
P(y_i = K \mid \mathbf{x}_i) = 
\frac{1}{
	1 + \sum_{j=1}^{K-1} \exp(\beta_{j0} + \mathbf{\beta}_j^\top \mathbf{x}_i)}.
\]

Здесь:
\begin{itemize}
	\item \( \beta_{k0} \) — свободный член для класса \( k \);
	\item \( \mathbf{\beta}_k = (\beta_{k1}, \beta_{k2}, \dots, \beta_{kp})^\top \in \mathbb{R}^p \) — вектор коэффициентов для класса \( k \).
\end{itemize}

\subsection{Функция правдоподобия}
Параметры модели оцениваются с помощью максимизации логарифма функции правдоподобия:
\[
\ell(\boldsymbol{\beta}) = \sum_{i=1}^n \sum_{k=1}^K \mathbb{1}(y_i = k) \ln P(y_i = k \mid \mathbf{x}_i),
\]
где:
\begin{itemize}
	\item \( \mathbb{1}(y_i = k) \) — индикатор принадлежности наблюдения \( i \)-му классу \( k \), равный 1, если \( y_i = k \), и 0 в противном случае;
	\item \( P(y_i = k \mid \mathbf{x}_i) \) задаётся формулой вероятности классов (см. выше).
\end{itemize}

\subsection{Процедура оптимизации}
Параметры \( \{\beta_{k0}, \mathbf{\beta}_k\}_{k=1}^{K-1} \) вычисляются с использованием численных методов оптимизации. Наиболее распространённые методы:
\begin{itemize}
	\item метод Ньютона-Рафсона, который использует градиенты и матрицу Гессе;
	\item итеративные методы максимального правдоподобия.
\end{itemize}

Градиент функции логарифмического правдоподобия по \( \boldsymbol{\beta} \) вычисляется как:
\[
\nabla_{\boldsymbol{\beta}} \ell(\boldsymbol{\beta}) = \sum_{i=1}^n \sum_{k=1}^K \mathbb{1}(y_i = k) 
\left[ \frac{\partial \ln P(y_i = k \mid \mathbf{x}_i)}{\partial \boldsymbol{\beta}} \right].
\]

\subsection{Предсказание значений}
Для оценки класса объекта по обученной модели используется следующий подход:

\begin{enumerate}
	\item Вычисляются вероятности принадлежности объекта каждому из \( K \) классов, используя формулы:
	\[
	\hat{P}(y = k \mid \mathbf{x}) = 
	\frac{\exp(\hat{\beta}_{k0} + \hat{\mathbf{\beta}}_k^\top \mathbf{x})}{
		1 + \sum_{j=1}^{K-1} \exp(\hat{\beta}_{j0} + \hat{\mathbf{\beta}}_j^\top \mathbf{x})}, 
	\quad k = 1, \dots, K-1,
	\]
	и для последнего класса (\( k = K \)):
	\[
	\hat{P}(y = K \mid \mathbf{x}) = \frac{1}{
		1 + \sum_{j=1}^{K-1} \exp(\hat{\beta}_{j0} + \hat{\mathbf{\beta}}_j^\top \mathbf{x})}.
	\]
	
	\item Определяется класс с максимальной вероятностью:
	\[
	\hat{y} = \arg\max_k \hat{P}(y = k \mid \mathbf{x}).
	\]
\end{enumerate}

\subsection{Оценка модели}
Оценка модели проводится с использованием различных метрик, включая матрицу путанности (confusion matrix) и анализ ROC-кривых. 

\subsubsection{Матрица путанности}
Матрица путанности показывает количество объектов, предсказанных и реальных, для каждого класса. Пример структуры матрицы для \( K \)-классовой задачи:
\[
\text{Confusion Matrix} = 
\begin{bmatrix}
	\text{TP}_{11} & \text{FP}_{12} & \cdots & \text{FP}_{1K} \\
	\text{FP}_{21} & \text{TP}_{22} & \cdots & \text{FP}_{2K} \\
	\vdots & \vdots & \ddots & \vdots \\
	\text{FP}_{K1} & \text{FP}_{K2} & \cdots & \text{TP}_{KK}
\end{bmatrix},
\]
где:
\begin{itemize}
	\item \( \text{TP}_{kk} \) — количество правильных предсказаний для класса \( k \) (true positives).
	\item \( \text{FP}_{ij} \) — количество объектов класса \( i \), ошибочно предсказанных как класс \( j \) (false positives).
\end{itemize}
Метрику точности (\textit{accuracy}), вычисляемую как:
\[
\text{Accuracy} = \frac{\text{Количество правильных предсказаний (диагональные элементы)}}{\text{Общее количество объектов}}.
\]
\[
\text{Accuracy} = \frac{\sum_k TP_{kk}}{\sum_k TP_{kk} + \sum_{j, j, i \ne j} FP_{ij}}.
\]

\subsubsection{ROC-кривые}
ROC (Receiver Operating Characteristic) кривые строятся для каждого класса \( k \) отдельно:
\begin{enumerate}
	\item Рассчитывается вероятность \( P(y = k \mid \mathbf{x}) \) для всех объектов.
	\item Выбираются различные пороги вероятности \( t \), чтобы предсказывать принадлежность к классу \( k \) (например, если \( P(y = k \mid \mathbf{x}) \geq t \), то предсказывается \( k \)).
	\item Для каждого порога вычисляются:
	\begin{itemize}
		\item Доля истинно положительных результатов (TPR):
		\[
		\text{TPR} = \frac{\text{TP}}{\text{TP} + \text{FN}}.
		\]
		\item Доля ложных положительных результатов (FPR):
		\[
		\text{FPR} = \frac{\text{FP}}{\text{FP} + \text{TN}}.
		\]
	\end{itemize}
	\item На графике \( (\text{FPR}, \text{TPR}) \) строится ROC-кривая.
\end{enumerate}

Площадь под ROC-кривой (\textit{Area Under Curve}, AUC) используется для количественной оценки качества модели: 
\[
\text{AUC} \in [0, 1].
\]
Чем ближе значение AUC к 1, тем лучше работает модель для классификации данного класса.

\subsection{Дополнение}
Для многоклассовых моделей оценивают средние значения метрик (например, ROC-AUC):
\[
\text{ROC-AUC}_{\text{macro}} = \frac{1}{K} \sum_{k=1}^K \text{AUC}_k.
\]

\section{Модель \texttt{ksvm} с ядром \texttt{rbfdot}}

Модель \texttt{ksvm} в пакете \texttt{kernlab} реализует метод опорных векторов (Support Vector Machine, SVM) для задач классификации или регрессии. Использование ядра \texttt{rbfdot} означает применение радиально-базисной функции (RBF kernel), которая позволяет обрабатывать нелинейно разделимые данные.

\subsection{Математическое описание}
Пусть у нас есть обучающая выборка \( \{(\mathbf{x}_i, y_i)\}_{i=1}^n \), где \( \mathbf{x}_i \in \mathbb{R}^p \) — вектор признаков, а \( y_i \in \{-1, +1\} \) для бинарной классификации или \( y_i \in \{1, 2, \dots, K\} \) для многоклассовой задачи.

Модель SVM решает следующую оптимизационную задачу:

\[
\min_{\mathbf{w}, b, \xi} \quad \frac{1}{2} \|\mathbf{w}\|^2 + C \sum_{i=1}^n \xi_i,
\]

при ограничениях:
\[
y_i \left( \mathbf{w}^\top \phi(\mathbf{x}_i) + b \right) \geq 1 - \xi_i, \quad \xi_i \geq 0, \quad i = 1, \dots, n.
\]

Здесь:
\begin{itemize}
	\item \( \mathbf{w} \) — весовой вектор модели;
	\item \( b \) — смещение (bias);
	\item \( \xi_i \) — штрафы за ошибочную классификацию (slack variables);
	\item \( C > 0 \) — гиперпараметр, регулирующий степень регуляризации (баланс между максимизацией отступа и минимизацией ошибок классификации);
	\item \( \phi(\mathbf{x}_i) \) — отображение в пространство большей размерности, определяемое ядром;
	\item \( \|\mathbf{w}\|^2 \) — квадрат нормы весов, который минимизируется для максимизации отступа.
\end{itemize}

\subsection{RBF-ядро}
Использование RBF-ядра (радиально-базисной функции) \texttt{rbfdot} определяет \(\phi(\mathbf{x}_i)\) косвенно через ядровую функцию:
\[
K(\mathbf{x}_i, \mathbf{x}_j) = \exp\left(-\gamma \|\mathbf{x}_i - \mathbf{x}_j\|^2\right),
\]
где \(\gamma > 0\) — параметр ядра, управляющий степенью воздействия расстояния между объектами на значения ядра.

RBF-ядро обладает высокой гибкостью, позволяя эффективно классифицировать данные с нелинейными границами.

\subsection{Вывод вероятностей}
Функция \texttt{ksvm} позволяет включить вероятностное моделирование (\texttt{prob.model = TRUE}). Это достигается через калибровку выходов модели методом Платта:
\[
P(y = +1 \mid \mathbf{x}) = \frac{1}{1 + \exp(A f(\mathbf{x}) + B)},
\]
где:
\begin{itemize}
	\item \( f(\mathbf{x}) = \mathbf{w}^\top \phi(\mathbf{x}) + b \) — дискриминантная функция SVM;
	\item \( A \) и \( B \) — параметры, оцениваемые методом минимизации логарифмической потери на обучающей выборке.
\end{itemize}

\subsection{Оценка модели}
Для оценки качества модели SVM используют:
\begin{itemize}
	\item Метрику точности (\textit{accuracy}), вычисляемую как:
	\[
	\text{Accuracy} = \frac{\text{Количество правильных предсказаний}}{\text{Общее количество объектов}}.
	\]
	\item Матрицу путанности для анализа ошибок.
	\item ROC-кривые и AUC для вероятностных предсказаний (при \( \texttt{prob.model = TRUE} \)).
	\item Среднюю кросс-энтропию, если модель калибрует вероятности:
	\[
	\text{Log Loss} = -\frac{1}{n} \sum_{i=1}^n \ln P(y_i \mid \mathbf{x}_i).
	\]
\end{itemize}

