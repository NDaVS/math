\setcounter{section}{0} % Устанавливаем начальное значение для раздела
\renewcommand\thesection{\arabic{section}} % Устанавливаем формат номера раздела как просто цифру
\label{cha:practice}

\chapter{Программная часть}
\section{Подготовка данных}
\begin{lstlisting}[language=R, caption={Импорт необходимых библиотек}]
library(nnet)
library(ggplot2)
library(dplyr)
library(caret)
library(pROC)
\end{lstlisting}

\begin{itemize}
	\item \textbf{nnet}: Библиотека для создания нейронных сетей. Основные функции: \texttt{nnet()} для построения многослойных перцептронов и обучение моделей с использованием обратного распространения ошибки.
	
	\item \textbf{ggplot2}: Библиотека для создания графиков и визуализации данных. Поддерживает создание различных типов графиков на основе грамматики графиков.
	
	\item \textbf{dplyr}: Библиотека для манипуляции данными. Обеспечивает функции для фильтрации, сортировки, группировки и агрегации данных, упрощая работу с дата-фреймами.
	
	\item \textbf{caret}: Библиотека для машинного обучения. Предоставляет единый интерфейс для создания, оценки и настройки моделей, а также функции для предобработки данных и оценки производительности.
	
	\item \textbf{pROC}: Библиотека для анализа ROC-кривых. Позволяет вычислять и визуализировать ROC-кривые и площадь под кривой (AUC), упрощая оценку качества классификаторов.
\end{itemize}

\begin{lstlisting}[language=R, caption={Загрузка датасета и задание сида}]
data <- read.table(file="flsr_moscow.txt", header = TRUE)
head(data)
summary(data)
dim(data)
print(colSums(sapply(data, is.na)))

set.seed(42)
\end{lstlisting}

Данный код загружает датасет \textbf{flsr\_moscow.txt} С учетом заголовков.
С помощью метода \textbf{head()}, просматриваются первые 6 строк данных:
\begin{table}
	\centering
	\caption{Данные объектов недвижимости}
	\begin{tabular}{@{}rrrrrrrrrr@{}}
		\toprule
		\# & price & nrooms & totsp & livesp & kitsp  & walk & \dots  & code \\ \midrule
		1  & 81    & 1      & 58    & 40     & 6            & 1    & \dots     & 3    \\
		2  & 75    & 1      & 44    & 28     & 6            & 1    & \dots     & 6    \\
		3  & 95    & 1      & 61    & 37     & 6            & 1    & \dots     &1    \\
		4  & 98    & 1      & 59    & 39     & 6           & 0    & \dots     & 8    \\
		5  & 88    & 1      & 55    & 36     & 6           & 1    & \dots     & 4    \\
		6  & 96    & 1      & 60    & 43     & 6           & 1    & \dots     & 7    \\ \bottomrule
	\end{tabular}
\end{table}

Также формируется общая информация о датасете с помощью метода \textbf{summary()}:
\begin{table}[h]
	\centering
	\caption{Сводная статистика объектов недвижимости}
	\begin{tabular}{@{}lrrrrrr@{}}
		\toprule
		Параметр & Min. & 1st Qu. & Median & Mean & 3rd Qu. & Max. \\ \midrule
		price       & 50.0   & 95.0     & 115.0  & 127.5  & 142.0   & 730.0  \\
		nrooms      & 1.000  & 1.000    & 2.500  & 2.491  & 3.000   & 4.000  \\
		totsp       & 44.00  & 62.00    & 73.50  & 73.08  & 79.00   & 192.00 \\
		livesp      & 28.00  & 42.00    & 45.00  & 46.34  & 50.00   & 102.00 \\
		kitsp       & 5.000  & 7.000    & 9.000  & 8.899  & 10.000  & 25.000 \\
		dist        & 3.00   & 9.00     & 12.00  & 11.02  & 13.50   & 17.00  \\
		metrdist    & 1.000  & 5.000    & 7.000  & 8.117  & 10.000  & 20.000 \\
		walk        & 0.0000 & 0.0000   & 1.0000 & 0.6858 & 1.0000  & 1.0000 \\
		brick       & 0.000  & 0.000    & 0.000  & 0.323  & 1.000   & 1.000  \\
		floor       & 0.0000 & 1.0000   & 1.0000 & 0.7907 & 1.0000  & 1.0000 \\
		code        & 1.000  & 3.000    & 4.000  & 4.322  & 6.000   & 8.000  \\ \bottomrule
	\end{tabular}
\end{table}

Проверка размерности датасета (\textbf{dim()}): 2040 строк и 11 столбцов.
\newline

Проверка на полноту датасета (\textbf{print(colSums(sapply(data, is.na)))}) - сумма na значений по столбцам:
\begin{table}[h]
	\centering
	\caption{Данные объектов недвижимости (нулевые значения)}
	\begin{tabular}{@{}rrrrrrrrrrr@{}}
		\toprule
		price & nrooms & totsp & livesp & kitsp & dist & metrdist & walk & brick & floor & code \\ \midrule
		0     & 0      & 0     & 0      & 0     & 0    & 0        & 0    & 0     & 0     & 0    \\ \bottomrule
	\end{tabular}
\end{table}

Также, зададим сид веротности, равный 42.


\begin{lstlisting}[label=R, caption={Формирование классов на основании переменной totsp}]
data$class <- cut(data$totsp, breaks = 4, labels = c("small", "medium", "large", "huge"))

data <- select(data, -totsp)
dim(data)
summary(data$class)
\end{lstlisting}

Данный код добавляет новое поле \textbf{class} в датасет. 
Тип - факторный с четырьмя уровнями.

Механизм деления: метод \textbf{cut} делит целевой набор (totsp) на 4 части (breaks) с наименованиями \textbf{labels}.

Далее, удаляется переменная \textbf{totsp}.
Проверяется размерность датасета: 2040 строк и 11 столбоцов. Ничего не было потеряно: один столбец убран и новый добавился.

Также выведем информацию по новому параметру:	
\begin{table}[h]
	\centering
	\caption{Частота уровней факторной переменной}
	\begin{tabular}{@{}lr@{}}
		\toprule
		Уровень & Частота \\ \midrule
		small   & 1672    \\
		medium  & 329     \\
		large   & 36      \\
		huge    & 3       \\ \bottomrule
	\end{tabular}
\end{table}
\newline\\

\begin{lstlisting}[language=R, caption={Формирвание обучающей, валидационной и тестовой выборок}]
train_index <- caret::createDataPartition(data$class, p = 0.6, list = FALSE)
train_data <- data[train_index, ]
temp_data <- data[-train_index, ]

validation_index <- caret::createDataPartition(temp_data$class, p = 0.5, list = FALSE)
validation_data <- temp_data[validation_index, ]
test_data <- temp_data[-validation_index, ]

cat("Size of train data:", dim(train_data), "\n")
cat("Size of validation data:", dim(validation_data), "\n")
cat("Size of test data:", dim(test_data), "\n")
\end{lstlisting}

\begin{enumerate}
	\item \textbf{Разбиение на тренировочные данные}:
	\begin{itemize}
		\item Функция \texttt{createDataPartition} из пакета \texttt{caret} используется для генерации индексов тренировочных данных. 
		\item Аргумент \texttt{p = 0.6} указывает, что 60\% от исходных данных будет отведено на тренировочную выборку.
		\item Сохраняются сами данные для тренировки: \texttt{train\_data}.
	\end{itemize}
	
	\item \textbf{Формирование временной выборки}:
	\begin{itemize}
		\item Оставшиеся 40\% данных (не вошедшие в тренировочную выборку) сохраняются в объекте \texttt{temp\_data}.
	\end{itemize}
	
	\item \textbf{Разбиение на валидационную и тестовую выборки}:
	\begin{itemize}
		\item 50\% от временной выборки назначаются валидационным данным с использованием той же функции \texttt{createDataPartition}.
		\item Оставшиеся 50\% становятся тестовыми данными.
		\item Данные сохраняются в \texttt{validation\_data} и \texttt{test\_data} соответственно.
	\end{itemize}
	
	\item \textbf{Вывод размеров выборок}:
	\begin{itemize}
		\item Используется функция \texttt{dim()} для определения количества строк и столбцов в каждой из подвыборок.
		\item Вывод осуществляется с помощью \texttt{cat()}.
	\end{itemize}
\end{enumerate}

Данные по размерности наборов предоставены ниже:
\begin{table}[h]
	\centering
	\caption{Размеры наборов данных}
	\begin{tabular}{@{}lrr@{}}
		\toprule
		Набор данных     & Количество наблюдений & Количество переменных \\ \midrule
		Обучающий        & 1226                  & 11                    \\
		Валидационный    & 408                   & 11                    \\
		Тестовый         & 406                   & 11                    \\ \bottomrule
	\end{tabular}
\end{table}

Можно заметить, что сумма количества наблюдей по выборкам в точности совпадает с изначальным значением количества наблюдейний

\section{Формирование softmax модели}

\begin{lstlisting}[language=R, caption={Формирование модели для классификации квартир}]
model <- multinom(class ~ ., data = train_data)

summary(model)
\end{lstlisting}

\begin{enumerate}
	\item \textbf{Создание модели}:
	\begin{itemize}
		\item Модель \texttt{multinom} применяется для решения многоклассовых задач классификации.
		\item Зависимая переменная (\texttt{class}) предсказывается на основе всех доступных признаков (\texttt{.} указывает на использование всех столбцов, кроме \texttt{class}).
		\item Данные для обучения берутся из \texttt{train\_data}.
	\end{itemize}
	
	\item \textbf{Вывод сведений о модели}:
	\begin{itemize}
		\item Команда \texttt{summary(model)} отображает коэффициенты регрессии (\( \beta_{kj} \)), их стандартные ошибки и соответствующие \( z \)-значения.
		\item Основная информация включает:
		\begin{enumerate}
			\item \textbf{Оценки коэффициентов:} \( \beta_{kj} \) для каждого признака \( j \) и класса \( k \), кроме базового.
			\item \textbf{Стандартные ошибки:} величина погрешности оценки коэффициентов.
	\end{enumerate}
	\end{itemize}
\end{enumerate}

\begin{table}[h]
	\centering
	\caption{Коэффициенты и стандартные ошибки модели множественной логистической регрессии}
	\begin{tabular}{@{}l|rrr|rrr@{}}
		\toprule
		Переменная & \multicolumn{3}{c|}{Коэффициенты} & \multicolumn{3}{c}{Стандартные ошибки} \\ \cmidrule{2-4} \cmidrule{5-7}
		& medium & large & huge & medium & large & huge \\ \midrule
		(Intercept) & -102.79 & -91.46 & -159.97 & 0.1659 & 0.5003 & 0.1399 \\
		price       & 0.0042  & 0.0250 & 0.1491  & 0.0054 & 0.0089 & 0.4578 \\
		nrooms      & 21.54   & 11.75  & -12.42  & 0.6635 & 2.0015 & 0.4848 \\
		livesp      & 0.279   & 0.519  & 0.778   & 0.0449 & 0.0887 & 2.6571 \\
		kitsp       & 0.155   & 0.424  & 3.656   & 0.0794 & 0.1474 & 3.1011 \\
		dist        & 0.013   & 0.461  & 1.964   & 0.0633 & 0.1981 & 3.9800 \\
		metrdist    & 0.045   & -0.071 & 2.527   & 0.0396 & 0.1364 & 4.0743 \\
		walk        & 0.107   & -1.139 & -12.587 & 0.3309 & 1.0230 & 0.3903 \\
		brick       & -0.819  & -2.945 & -11.131 & 0.3915 & 1.1379 & 0.2262 \\
		floor       & 0.508   & 0.197  & 8.474   & 0.4004 & 2.0680 & 0.1399 \\
		code        & 0.032   & 0.019  & 0.778   & 0.0776 & 0.2517 & 0.9684 \\ \bottomrule
	\end{tabular}
\end{table}


Также, информация о модели содержит такие показатели, как \textit{Residual Deviance} и \textit{AIC}.
 Их значения дают представление о качестве модели и её способности предсказывать целевую переменную.

\subsection*{Residual Deviance (Остаточная девиация)}

\textbf{Остаточная девиация} является мерой, отражающей степень отклонения предсказаний модели от истинных значений целевой переменной.

\begin{itemize}
	\item Расчёт остаточной девиации основан на функции логарифма правдоподобия (\( \text{Log-Likelihood} \)):
	\[
	\text{Residual Deviance} = -2 \times \text{Log-Likelihood}.
	\]
	\item Для данной модели \texttt{Residual Deviance = 312.5433}.
	\item Меньшие значения остаточной девиации указывают на лучшее соответствие модели данным.
	\item Остаточная девиация обычно сравнивается с начальной девиацией (\textit{Null Deviance}), которая оценивает правдоподобие модели только с учетом базового уровня (без учёта признаков).
\end{itemize}

\subsubsection*{Интерпретация}
\begin{itemize}
	\item Если модель сильно уменьшила девиацию относительно начальной (\( \text{Null Deviance} \gg \text{Residual Deviance} \)), то это указывает на хороший учёт информации в данных.
	\item Если разница мала, модель может быть недостаточно информативной.
\end{itemize}

\subsection*{AIC (Критерий Акаике)}

\textbf{AIC} (\textit{Akaike Information Criterion}) используется для оценки качества модели с учётом её сложности. 

\begin{itemize}
	\item Формула расчёта AIC:
	\[
	\text{AIC} = -2 \times \text{Log-Likelihood} + 2 \times k,
	\]
	где:
	\begin{itemize}
		\item \( \text{Log-Likelihood} \) — логарифм функции правдоподобия модели;
		\item \( k \) — число параметров модели (включая смещение и коэффициенты).
	\end{itemize}
	\item Для данной модели: \texttt{AIC = 378.5433}.
	\item Критерий включает штраф за увеличение числа параметров модели, чтобы избежать переобучения.
	\item Меньшее значение AIC указывает на лучшую модель с учётом её предсказательной силы и сложности.
\end{itemize}

\subsubsection*{Интерпретация}
\begin{itemize}
	\item AIC полезен при сравнении нескольких моделей: модель с наименьшим значением AIC предпочтительнее.
	\item Следует избегать исключительно снижения AIC, если это приводит к потере интерпретируемости.
\end{itemize}

\subsection{Оценка модели}
\begin{lstlisting}[language=R, caption={Проверка модели на валидационном наборе данных}]	
validation_predictions <- predict(model, validation_data)
validation_pred_prob <- predict(model, validation_data, type="prob")
head(validation_predictions)
head(validation_pred_prob)
\end{lstlisting}

\begin{enumerate}
	\item \textbf{Предсказание классов (\texttt{predict})}:
	\begin{itemize}
		\item Функция \texttt{predict()} используется для генерации предсказаний модели.
		\item Параметры:
		\begin{itemize}
			\item \texttt{model} — обученная модель \texttt{multinom}.
			\item \texttt{validation\_data} — данные для валидации.
		\end{itemize}
		\item По умолчанию, функция возвращает предсказанный класс для каждой строки валидационного набора.
		\item Результаты сохраняются в \texttt{validation\_predictions}.
	\end{itemize}
	
	\item \textbf{Предсказание вероятностей классов (\texttt{type="prob"})}:
	\begin{itemize}
		\item Указание параметра \texttt{type="prob"} в функции \texttt{predict()} приводит к возврату вероятностей принадлежности каждого объекта к каждому классу.
		\item Возвращаемый результат представляет собой таблицу (матрицу), где:
		\[
		\text{Строка \( i \)} \Rightarrow \text{вероятности для объекта \( i \) по всем классам}.
		\]
		\item Результаты сохраняются в \texttt{validation\_pred\_prob}.
	\end{itemize}
	
	\item \textbf{Отображение результатов (\texttt{head})}:
\end{enumerate}

Первый head вывел в консоль 6 раз small.
\newline

\newpage
Второй:
\begin{table}[h]
	\centering
	\caption{Таблица вероятностей подсказаний класса}
	\begin{tabular}{lllll}
		\# & small & medium & large & huge \\
		5 & 1 & 3.372637e-31 & 2.892411e-25 & 5.541612e-44 \\
		7 & 1 & 6.063928e-30 & 1.520350e-21 & 3.105919e-26 \\
		9 & 1 & 7.695684e-31 & 1.409279e-24 & 1.355995e-27 \\
		12 & 1 & 8.907091e-30 & 2.725440e-21 & 9.451532e-32 \\
		15 & 1 & 7.922207e-31 & 1.566323e-23 & 3.258361e-32 \\
		19 & 1 & 7.564271e-31 & 2.971952e-24 & 1.462170e-35 \\
	\end{tabular}
\end{table}




\subsection{Оценка значимости}
\begin{lstlisting}[language=R, caption={Формирование метрик значимости}]
coef_summary <- summary(model)

coefficients <- coef_summary$coefficients

estimates <- coefficients
std_errors <- coef_summary$standard.errors

alpha <- 0.05
z_alpha_over_2 <- qnorm(1 - alpha / 2) 


lower_bounds <- estimates - z_alpha_over_2 * std_errors
upper_bounds <- estimates + z_alpha_over_2 * std_errors


confidence_intervals <- data.frame(
Coefficient = estimates,
Lower_Bound = lower_bounds,
Upper_Bound = upper_bounds
)


print(confidence_intervals)

z_scores <- coefficients / std_errors
p_values <- 2 * (1 - pnorm(abs(z_scores)))

cat("\nP-value:\n")
print(p_values)
\end{lstlisting}
\subsection*{Шаги выполнения}

\begin{enumerate}
	\item \textbf{Получение коэффициентов модели (\texttt{coef\_summary\$coefficients}):}
	\begin{itemize}
		\item Результаты модели извлекаются с помощью \texttt{summary(model)}. Это позволяет получить информацию о коэффициентах модели.
	\end{itemize}
	
	\item \textbf{Расчёт доверительных интервалов:}
	\begin{itemize}
		\item Доверительный интервал для каждого коэффициента рассчитывается на основе оценки коэффициента (\texttt{estimates}) и стандартной ошибки (\texttt{std\_errors}).
		\item Используем критическое значение \( z_{\alpha / 2} \), которое получаем через функцию \texttt{qnorm}, основываясь на заданном уровне значимости \( \alpha \) (например, 0.05).
		\item Нижний и верхний пределы доверительного интервала вычисляются как:
		\[
		\text{Lower Bound} = \text{Coefficient} - z_{\alpha/2} \times \text{SE}
		\]
		\[
		\text{Upper Bound} = \text{Coefficient} + z_{\alpha/2} \times \text{SE}
		\]
		\item Результат сохраняется в \texttt{confidence\_intervals} и выводится с помощью \texttt{print}.
	\end{itemize}
	
	\item \textbf{Расчёт p-значений:}
	\begin{itemize}
		\item Для каждого коэффициента вычисляется статистика \( z \) с использованием формулы:
		\[
		z = \frac{\text{Coefficient}}{\text{Standard Error}}
		\]
		\item После вычисления \( z \)-значений, p-значения рассчитываются как \( 2 \times (1 - \text{pnorm}(\left|z\right|)) \), где \texttt{pnorm} вычисляет вероятность нормального распределения для заданной \( z \)-статистики.
		\item Вычисленные p-значения выводятся с помощью \texttt{print}.
	\end{itemize}
\end{enumerate}

\subsection*{Интерпретация}

1. \textbf{Доверительные интервалы:} Для каждого коэффициента модели вычисляются доверительные интервалы, что позволяет оценить, в каком диапазоне может лежать истинное значение коэффициента с заданной вероятностью.

2. \textbf{P-значения:} P-значения указывают на статистическую значимость коэффициентов. Если p-значение меньше уровня значимости (например, \( \alpha = 0.05 \)), то коэффициент считается статистически значимым и влияющим на модель.




\begin{sidewaystable}
	\centering
	\caption{Таблица коэффициентов и доверительных интервалов}
	\begin{tabular}{lrrrrrrr}
		\toprule
		& \multicolumn{3}{c}{Coefficient} & \multicolumn{3}{c}{95\% CI} \\
		\cmidrule(lr){2-4} \cmidrule(lr){5-7}
		Переменная & medium & large & huge & medium & large & huge \\
		\midrule
		Intercept & -102.79208 & -91.46012 & -159.97239 & [-103.12, -102.47] & [-92.44, -90.48] & [-160.25, -159.70] \\
		price & 0.004242476 & 0.025008955 & 0.149126243 & [-0.01, 0.02] & [0.01, 0.04] & [-0.75, 1.05] \\
		nrooms & 21.53842 & 11.75132 & -12.41825 & [20.24, 22.84] & [7.83, 15.67] & [-13.37, -11.47] \\
		livesp & 0.2786031 & 0.5188833 & 0.7784897 & [0.19, 0.37] & [0.35, 0.69] & [-4.43, 5.99] \\
		kitsp & 0.1548881 & 0.4237548 & 3.6559646 & [-0.00, 0.31] & [0.13, 0.71] & [-2.42, 9.73] \\
		dist & 0.01299013 & 0.46108441 & 1.96394778 & [-0.11, 0.14] & [0.07, 0.85] & [-5.84, 9.76] \\
		metrdist & 0.04477751 & -0.07134023 & 2.52728122 & [-0.03, 0.12] & [-0.34, 0.20] & [-5.46, 10.51] \\
		walk & 0.1066931 & -1.1392639 & -12.5871572 & [-0.54, 0.76] & [-3.14, 0.87] & [-13.35, -11.82] \\
		brick & -0.8189447 & -2.9454035 & -11.1312490 & [-1.59, -0.05] & [-5.18, -0.72] & [-11.57, -10.69] \\
		floor & 0.5078203 & 0.1969960 & 8.4744960 & [-0.28, 1.29] & [-3.86, 4.25] & [8.20, 8.75] \\
		code & 0.03207142 & 0.01868934 & 0.77778279 & [-0.12, 0.18] & [-0.47, 0.51] & [-1.12, 2.68] \\
		\bottomrule
	\end{tabular}
\end{sidewaystable}

\newpage 
Уже видно по доверительным интервалам, что модель некорректна.

Для корректировки модели определим статистически незначимые параметры с помощью P-value:


\begin{table}[h]
	\centering
	\caption{Таблица p-значений}
	\begin{tabular}{|l|r|r|r|rrrrrrrr}
		\toprule
		& \multicolumn{3}{|c|}{p-value} \\
		\cmidrule(lr){2-4}
		Переменная & medium & large & huge \\
		\midrule
		(Intercept) & 0.0000000 & 0.0000000 & 0.0000000 \\
		price & 0.4322993 & 0.0047229 & 0.7446396 \\
		nrooms & 0.0000000 & 0.0000000 & 0.0000000 \\
		livesp & 0.0000001 & 0.0000005 & 0.7695377 \\
		kitsp & 0.0510531 & 0.0040345 & 0.2384270 \\
		dist & 0.8375105 & 0.0199534 & 0.6216908 \\
		metrdist & 0.2586784 & 0.6010639 & 0.5350591 \\
		walk & 0.7471466 & 0.2654454 & 0.0000000 \\
		brick & 0.0364589 & 0.0096421 & 0.0000000 \\
		floor & 0.2046657 & 0.9241072 & 0.0000000 \\
		code & 0.6794891 & 0.9408164 & 0.4218866 \\
		\bottomrule
	\end{tabular}
\end{table}

Отсюда видно, что значимыми параметрами являются только константа, \textbf{nrooms} и \textbf{livesp} (параметров для large и huge крайне мало, так что на эти метрики можно не смотреть. Убрать их нельзя, т.к. модель должна работать для классификации четрыёх классов). 

Сформируем модель, основываясь только на этих параметрах. 

\subsection{Оптимальная модель}
\begin{lstlisting}[language=R, caption={Построение оптимальной модели}]
model <- multinom(class ~ nrooms + livesp, data = train_data)
\end{lstlisting}
\newpage

После проведения тех же процедур оценки на валидационной выборке, модель преобрела статистически значимые параметры и её точность выросла почти на процент. 
\begin{table}[h]
	\centering
	\caption{Коэффициенты и стандартные ошибки модели множественной логистической регрессии}
	\begin{tabular}{@{}l|rrr|rrr@{}}
		\toprule
		Переменная & \multicolumn{3}{c|}{Коэффициенты} & \multicolumn{3}{c}{Стандартные ошибки} \\ \cmidrule{2-4} \cmidrule{5-7}
		& medium & large & huge & medium & large & huge \\ \midrule
		(Intercept) & -94.29 & -67.20 & -62.32 & 0.097 & 0.18 & 0.46 \\
		nrooms      & 20.83 & 10.08 & 6.38  & 0.39  & 0.71  & 1.84  \\
		livesp      & 0.23 & 0.45 & 0.54 & 0.032 & 0.05 & 0.10 \\ \bottomrule
	\end{tabular}
\end{table}

\textit{Residual Deviance}: 381

\textit{AIC}: 399

Хоть, разделённая разность больше, но критерий AIC показывает, что данная модель выигрывает, по сравнению с не оптимизированной (387).





\begin{table}[h]
	\centering
	\caption{P-value оптимизированной модели}
	\begin{tabular}{@{}l|rrr@{}}
		\toprule
		Переменная & medium & large & huge \\ \midrule
		(Intercept) & 0 & 0 & 0 \\
		nrooms      & 0.0000000000 & 0.0000000000 & 0.0005313391 \\
		livesp      & 3.124612e-12 & 0.000000e+00 & 1.430513e-07 \\ \bottomrule
	\end{tabular}
\end{table}
Можно наблюдать, что \textbf{все} параметры являются значимимы.

\begin{table}[h]
	\centering
	\caption{Коэффициенты и доверительные интервалы модели множественной логистической регрессии}
	\begin{tabular}{@{}l|rrr|rrr@{}}
		\toprule
		Переменная & \multicolumn{3}{c|}{Коэффициенты} & \multicolumn{3}{c}{Доверительные интервалы} \\ \cmidrule{2-4} \cmidrule{5-7}
		& medium & large & huge & Lower Bound & Upper Bound \\ \midrule
		Intercept & -94.28639 & -67.20221 & -62.32092 & -94.47669 & -94.09608 \\
		nrooms    & 20.832198 & 10.076997 & 6.376026  & 20.070977 & 21.593419 \\
		livesp    & 0.2272280 & 0.4462840 & 0.5451541 & 0.1633498 & 0.7482380 \\ \bottomrule
	\end{tabular}
\end{table}
Данная таблица иллюстрирует, что концы доверительных интервалов имеют один знак, и находятся на довольно малом расстоянии.

\subsection*{Промежуточные выводы}
Удалось оптимизировать параметры модели, перейдя с 10 до 2 штук. Что позволило увеличить критерий AIC и статистически добиться значимости параметров. 

Следующим шагом будет являться использование модели на тестовых данных.

\subsection{Финальные тест}
Для демонстрации результатов, модели будет передан тестовый набор параметров. На основании анализа результатов можно будет сделать выводы о точности предсказаний.

\section*{Матрица путаницы и статистики классификации}

\begin{lstlisting}[language=R, caption={Формирование матрицы путаницы}]
misclassification<-caret::confusionMatrix(data=test_predictions ,reference=test_data$class)
misclassification
\end{lstlisting}

\subsection*{Матрица путаницы}

Результаты классификации модели:

\[
\begin{array}{|c|c|c|c|c|}
	\hline
	\textbf{Prediction $\backslash$ Reference} & \textbf{small} & \textbf{medium} & \textbf{large} & \textbf{huge} \\
	\hline
	\textbf{small} & 326 & 12 & 0 & 0 \\
	\hline
	\textbf{medium} & 8 & 52 & 5 & 0 \\
	\hline
	\textbf{large} & 0 & 1 & 1 & 0 \\
	\hline
	\textbf{huge} & 0 & 0 & 1 & 0 \\
	\hline
\end{array}
\]

\subsection*{Общая статистика}

\begin{itemize}
	\item \textbf{Accuracy (Точность):} \( 93.35\% \)
	\item \textbf{95\% Доверительный интервал (CI):} \( (90.47\%, 95.57\%) \)
	\item \textbf{No Information Rate (NIR):} \( 82.27\% \)
	\item \textbf{P-Value [Acc > NIR]:} \( 5.826 \times 10^{-11} \)
	\item \textbf{Коэффициент Kappa:} \( 0.7702 \)
	\item \textbf{Тест МакНемара:} Недоступен (\textit{NA})
\end{itemize}

\subsection*{Статистика по классам}

Таблица ниже содержит метрики для каждого класса:

\[
\begin{array}{|l|c|c|c|c|}
	\hline
	\textbf{Метрика} & \textbf{ small} & \textbf{ medium} & \textbf{ large} & \textbf{ huge} \\
	\hline
	\textbf{Sensitivity } & 0.9760 & 0.8000 & 0.1429 & \textit{NA} \\
	\hline
	\textbf{Specificity} & 0.8333 & 0.9619 & 0.9975 & 0.9975 \\
	\hline
	\textbf{Pos Pred Value } & 0.9645 & 0.8000 & 0.5000 & \textit{NA} \\
	\hline
	\textbf{Neg Pred Value } & 0.8824 & 0.9619 & 0.9851 & \textit{NA} \\
	\hline
	\textbf{Prevalence} & 0.8227 & 0.1601 & 0.0172 & 0.0000 \\
	\hline
	\textbf{Detection Rate} & 0.8030 & 0.1281 & 0.0025 & 0.0000 \\
	\hline
	\textbf{Detection Prevalence} & 0.8325 & 0.1601 & 0.0049 & 0.0025 \\
	\hline
	\textbf{Balanced Accuracy} & 0.9047 & 0.8809 & 0.5702 & \textit{NA} \\
	\hline
\end{array}
\]

\subsection*{Интерпретация}

\begin{itemize}
	\item \textbf{Чувствительность (Sensitivity):} Показывает, какая доля объектов каждого класса была правильно классифицирована.
	\item \textbf{Специфичность (Specificity):} Указывает на способность модели корректно классифицировать объекты, которые не принадлежат к рассматриваемому классу.
	\item \textbf{Сбалансированная точность (Balanced Accuracy):} Учитывает баланс между чувствительностью и специфичностью для каждого класса.
	\item \textbf{Прогностическая ценность (PPV, NPV):} PPV показывает вероятность того, что предсказанный класс является правильным, а NPV — что объект не принадлежит к рассматриваемому классу.
\end{itemize}

\subsection*{Результаты анализа ROC-кривых и значений AUC}
\begin{lstlisting}[language=R, caption={Построение и анализ ROC-кривых}]
test_pred_prob <- predict(model, test_data, type = "prob")

roc_list <- list()
auc_list <- c()

for (class in colnames(test_pred_prob)) {
	binary_true_labels <- ifelse(test_data$class == class, 1, 0)
	

	if (length(unique(binary_true_labels)) == 2) {
		roc_curve <- roc(binary_true_labels, test_pred_prob[, class], quiet = TRUE)
		roc_list[[class]] <- roc_curve
		
		auc_list <- c(auc_list, auc(roc_curve))
		
		cat(paste("Class:", class, "- AUC:", round(auc(roc_curve), 3)), "\n")
	} else {
		cat(paste("Class:", class, "- not enought data for draw ROC-curve\n"))
	}
}
plot(roc_list[[1]], col = "blue", main = "ROC-curve (One-vs-Rest)", lwd = 2)
for (i in 2:length(roc_list)) {
	plot(roc_list[[i]], col = i, add = TRUE, lwd = 2)
}
legend("bottomright", legend = colnames(test_pred_prob), col = 1:length(roc_list), lwd = 2)


\end{lstlisting}

Ниже представлены результаты вычислений ROC-кривых и площадей под кривой (AUC) для каждого класса целевой переменной:

\begin{longtable}{|c|c|}
	\hline
	\textbf{Класс} & \textbf{AUC} \\ 
	\hline
	\texttt{small}  & 0.989 \\
	\texttt{medium} & 0.981 \\
	\texttt{large}  & 0.996 \\
	\texttt{huge}   & \textbf{Недостаточно уровней для построения ROC-кривой} \\
	\hline
\end{longtable}

\subsection*{Описание результатов}
\begin{itemize}
	\item \textbf{Класс small:} Значение AUC составило 0.989, что свидетельствует о высокой способности модели различать данный класс от остальных.
	\item \textbf{Класс medium:} Значение AUC составляет 0.981, что также указывает на высокую точность классификации данного класса.
	\item \textbf{Класс large:} Наивысшее значение AUC среди классов — 0.996, Но этот показатель вызван нехваткой данных, т.к. выборка крайне неоднородна.
	\item \textbf{Класс huge:} Для данного класса не удалось построить ROC-кривую, так как в целевых данных отсутствовали оба уровня (0 и 1), необходимых для анализа.
\end{itemize}

Также, приведём визуализацию предсказанных классов в срезе \textbf{class} и \textbf{nrooms}


\subsection{Вывод по классификации softmax}

По результатам построения модели можно сказать, что она с очень хорошей точностью предсказывает классификацию для квартир класса small и medium. Но для класса \textbf{large} модель работает хуже, а предсказание класса \textbf{huge} очень плохое. 

Такое поведение объясняется неоднородностью данных в датасете. 

Таким образом, оптимальным решением будет использовать модель для бинарной классификации в рамках множества \{small, medium\}.

\section{SVM-модель}

В качестве SVM моедли будем использовать ksvm-модель из пакета \textbf{kernlab}.





